{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "harmful-skill",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "amber-nudist",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'oliver twist.txt'\n",
    "raw_data = open(file,'r',encoding = 'utf-8').read()\n",
    "raw_data = raw_data.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "light-southeast",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ngles with new associates. going to a funeral for '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data[1300:1350]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "expressed-federal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "913035\n"
     ]
    }
   ],
   "source": [
    "print(len(raw_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "analyzed-horse",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set(raw_data))\n",
    "chartoint = {u:i for i ,u in enumerate(vocab)}\n",
    "inttochar = np.array(vocab)\n",
    "text2int = np.array([chartoint[c] for c in raw_data])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "departmental-dependence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chartoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "lonely-newman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique/Special characters\n",
      "\n",
      "\n",
      "'\\n'   0\n",
      "' '    1\n",
      "'!'    2\n",
      "'\"'    3\n",
      "'#'    4\n",
      "'$'    5\n",
      "'%'    6\n",
      "\"'\"    7\n",
      "'('    8\n",
      "')'    9\n",
      "'*'   10\n",
      "','   11\n",
      "'-'   12\n",
      "'.'   13\n",
      "'/'   14\n",
      "'0'   15\n",
      "'1'   16\n",
      "'2'   17\n",
      "'3'   18\n",
      "'4'   19\n",
      "'5'   20\n",
      "'6'   21\n",
      "'7'   22\n",
      "'8'   23\n",
      "'9'   24\n",
      "':'   25\n",
      "';'   26\n",
      "'?'   27\n",
      "'@'   28\n",
      "'['   29\n",
      "']'   30\n",
      "'_'   31\n",
      "'a'   32\n",
      "'b'   33\n",
      "'c'   34\n",
      "'d'   35\n",
      "'e'   36\n",
      "'f'   37\n",
      "'g'   38\n",
      "'h'   39\n",
      "'i'   40\n",
      "'j'   41\n",
      "'k'   42\n",
      "'l'   43\n",
      "'m'   44\n",
      "'n'   45\n",
      "'o'   46\n",
      "'p'   47\n",
      "'q'   48\n",
      "'r'   49\n",
      "'s'   50\n",
      "'t'   51\n",
      "'u'   52\n",
      "'v'   53\n",
      "'w'   54\n",
      "'x'   55\n",
      "'y'   56\n",
      "'z'   57\n",
      "'—'   58\n",
      "'‘'   59\n",
      "'’'   60\n",
      "'“'   61\n",
      "'”'   62\n",
      "'\\ufeff'  63\n"
     ]
    }
   ],
   "source": [
    "print('Unique/Special characters')\n",
    "print('\\n')\n",
    "for char,_ in zip(chartoint,range(64)):\n",
    "    print('{:4s} {:3d}'.format(repr(char),chartoint[char]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "alike-thong",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e anywhere in the united states and most\n",
      "other parts of the world at no cost and with almost no restrictions\n",
      "whatsoever.  you may copy it, give it away or re-use it under the terms of\n",
      "the project gute \n",
      "\n",
      "----chartoint visualization----\n",
      "\n",
      " [36  1 32 45 56 54 39 36 49 36  1 40 45  1 51 39 36  1 52 45 40 51 36 35\n",
      "  1 50 51 32 51 36 50  1 32 45 35  1 44 46 50 51  0 46 51 39 36 49  1 47\n",
      " 32 49 51 50  1 46 37  1 51 39 36  1 54 46 49 43 35  1 32 51  1 45 46  1\n",
      " 34 46 50 51  1 32 45 35  1 54 40 51 39  1 32 43 44 46 50 51  1 45 46  1\n",
      " 49 36 50 51 49 40 34 51 40 46 45 50  0 54 39 32 51 50 46 36 53 36 49 13\n",
      "  1  1 56 46 52  1 44 32 56  1 34 46 47 56  1 40 51 11  1 38 40 53 36  1\n",
      " 40 51  1 32 54 32 56  1 46 49  1 49 36 12 52 50 36  1 40 51  1 52 45 35\n",
      " 36 49  1 51 39 36  1 51 36 49 44 50  1 46 37  0 51 39 36  1 47 49 46 41\n",
      " 36 34 51  1 38 52 51 36]\n"
     ]
    }
   ],
   "source": [
    "print(raw_data[100:300],'\\n\\n----chartoint visualization----\\n\\n',text2int[100:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "complex-wagon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "\n",
    "sq_len = 100\n",
    "example_epochs = len(raw_data) // (sq_len +1)\n",
    "chardataset = tensorflow.data.Dataset.from_tensor_slices(text2int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "narrative-vegetarian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿\n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "p\n",
      "r\n",
      "o\n",
      "j\n",
      "e\n"
     ]
    }
   ],
   "source": [
    "for c in chardataset.take(10):\n",
    "    print(inttochar[c.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "harmful-period",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\\ufeffthe project gutenberg ebook of oliver twist, by charles dickens\\n\\nthis ebook is for the use of anyone'\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "' anywhere in the united states and most\\nother parts of the world at no cost and with almost no restri'\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "'ctions\\nwhatsoever.  you may copy it, give it away or re-use it under the terms of\\nthe project gutenbe'\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "'rg license included with this ebook or online at\\nwww.gutenberg.org.  if you are not located in the un'\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\"ited states, you'll have\\nto check the laws of the country where you are located before using this ebo\"\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "'ok.\\n\\ntitle: oliver twist\\n\\nauthor: charles dickens\\n\\nrelease date: november, 1996 [ebook #730]\\n[most re'\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "'cently updated: november 28, 2020]\\n\\nlanguage: english\\n\\ncharacter set encoding: utf-8\\n\\n*** start of th'\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "'is project gutenberg ebook oliver twist ***\\n\\n\\n\\n\\nproduced by peggy gaugy and leigh little.  html versi'\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "'on by al haines.\\n\\n\\n\\n\\noliver twist\\n\\nor\\nthe parish boy’s progress\\n\\nby charles dickens\\n\\n\\ncontents\\n\\ni    '\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "'    treats of the place where oliver twist was born and of the\\n         circumstances attending his b'\n",
      "------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "sequences = chardataset.batch(sq_len+1, drop_remainder = True)\n",
    "for i in sequences.take(10):\n",
    "    print(repr(''.join(inttochar[i.numpy()])) )\n",
    "    print('------'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "stone-arthur",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_tar(data):\n",
    "    input_ = data[:-1]\n",
    "    target = data[1:]\n",
    "    return input_ , target\n",
    "dataset = sequences.map(split_input_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "wicked-iceland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\\ufeffthe project gutenberg ebook of oliver twist, by charles dickens\\n\\nthis ebook is for the use of anyon'\n",
      "'the project gutenberg ebook of oliver twist, by charles dickens\\n\\nthis ebook is for the use of anyone'\n"
     ]
    }
   ],
   "source": [
    "for input_ex , target_ex in dataset.take(1):\n",
    "    print(repr(''.join(inttochar[input_ex.numpy()])))\n",
    "    print(repr(''.join(inttochar[target_ex.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "after-helen",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 30\n",
    "BUFFER_SIZE = 10000\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "abandoned-actress",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape <BatchDataset shapes: ((30, 100), (30, 100)), types: (tf.int32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "print('Shape {}'.format(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "designing-fighter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (30, None, 256)           16384     \n",
      "_________________________________________________________________\n",
      "gru_4 (GRU)                  (30, None, 1024)          3938304   \n",
      "_________________________________________________________________\n",
      "gru_5 (GRU)                  (30, None, 128)           443136    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (30, None, 64)            8256      \n",
      "=================================================================\n",
      "Total params: 4,406,080\n",
      "Trainable params: 4,406,080\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense, GRU, Dropout, Embedding\n",
    "from tensorflow.keras.models import Sequential\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(vocab),256,batch_input_shape= [BATCH_SIZE,None]))\n",
    "model.add(GRU(1024, return_sequences = 'True', stateful = True, recurrent_initializer = 'glorot_uniform'))\n",
    "model.add(GRU(128, return_sequences = 'True', stateful = True, recurrent_initializer = 'glorot_uniform'))\n",
    "model.add(Dense(len(vocab)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "sapphire-gibson",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "loss = SparseCategoricalCrossentropy(from_logits = True, )\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "hawaiian-retreat",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, datetime\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "path = r'Predictive text generation/training_checkpoints'\n",
    "file = os.path.join(path,\"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath = file, save_weights_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "identical-blues",
   "metadata": {},
   "outputs": [],
   "source": [
    "logdr = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tb = TensorBoard(logdr, histogram_freq = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "brilliant-eclipse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "301/301 [==============================] - 394s 1s/step - loss: 2.1934\n",
      "Epoch 2/64\n",
      "301/301 [==============================] - 401s 1s/step - loss: 1.8820\n",
      "Epoch 3/64\n",
      "301/301 [==============================] - 381s 1s/step - loss: 1.6936\n",
      "Epoch 4/64\n",
      "301/301 [==============================] - 398s 1s/step - loss: 1.5707\n",
      "Epoch 5/64\n",
      "301/301 [==============================] - 3218s 11s/step - loss: 1.4862\n",
      "Epoch 6/64\n",
      "301/301 [==============================] - 389s 1s/step - loss: 1.4219\n",
      "Epoch 7/64\n",
      "301/301 [==============================] - 386s 1s/step - loss: 1.3721\n",
      "Epoch 8/64\n",
      "301/301 [==============================] - 383s 1s/step - loss: 1.3332\n",
      "Epoch 9/64\n",
      "301/301 [==============================] - 384s 1s/step - loss: 1.2977\n",
      "Epoch 10/64\n",
      "301/301 [==============================] - 385s 1s/step - loss: 1.2678\n",
      "Epoch 11/64\n",
      "301/301 [==============================] - 391s 1s/step - loss: 1.2404\n",
      "Epoch 12/64\n",
      "301/301 [==============================] - 393s 1s/step - loss: 1.2140\n",
      "Epoch 13/64\n",
      "301/301 [==============================] - 385s 1s/step - loss: 1.1896\n",
      "Epoch 14/64\n",
      "301/301 [==============================] - 391s 1s/step - loss: 1.1647\n",
      "Epoch 15/64\n",
      "301/301 [==============================] - 377s 1s/step - loss: 1.1411\n",
      "Epoch 16/64\n",
      "301/301 [==============================] - 387s 1s/step - loss: 1.1234\n",
      "Epoch 17/64\n",
      "301/301 [==============================] - 419s 1s/step - loss: 1.0960\n",
      "Epoch 18/64\n",
      "301/301 [==============================] - 396s 1s/step - loss: 1.0735\n",
      "Epoch 19/64\n",
      "301/301 [==============================] - 376s 1s/step - loss: 1.0527\n",
      "Epoch 20/64\n",
      "301/301 [==============================] - 375s 1s/step - loss: 1.0334\n",
      "Epoch 21/64\n",
      "301/301 [==============================] - 370s 1s/step - loss: 1.0150\n",
      "Epoch 22/64\n",
      "301/301 [==============================] - 368s 1s/step - loss: 0.9947\n",
      "Epoch 23/64\n",
      "301/301 [==============================] - 369s 1s/step - loss: 0.9783\n",
      "Epoch 24/64\n",
      "301/301 [==============================] - 369s 1s/step - loss: 0.9609\n",
      "Epoch 25/64\n",
      "301/301 [==============================] - 369s 1s/step - loss: 0.9448\n",
      "Epoch 26/64\n",
      "301/301 [==============================] - 369s 1s/step - loss: 0.9274\n",
      "Epoch 27/64\n",
      "301/301 [==============================] - 368s 1s/step - loss: 0.9140\n",
      "Epoch 28/64\n",
      "301/301 [==============================] - 367s 1s/step - loss: 0.8999\n",
      "Epoch 29/64\n",
      "301/301 [==============================] - 368s 1s/step - loss: 0.8853\n",
      "Epoch 30/64\n",
      "301/301 [==============================] - 368s 1s/step - loss: 0.8722\n",
      "Epoch 31/64\n",
      "301/301 [==============================] - 368s 1s/step - loss: 0.8598\n",
      "Epoch 32/64\n",
      "301/301 [==============================] - 367s 1s/step - loss: 0.8490\n",
      "Epoch 33/64\n",
      "301/301 [==============================] - 368s 1s/step - loss: 0.8377\n",
      "Epoch 34/64\n",
      "301/301 [==============================] - 368s 1s/step - loss: 0.8276\n",
      "Epoch 35/64\n",
      "301/301 [==============================] - 380s 1s/step - loss: 0.8166\n",
      "Epoch 36/64\n",
      "301/301 [==============================] - 382s 1s/step - loss: 0.8089\n",
      "Epoch 37/64\n",
      "301/301 [==============================] - 383s 1s/step - loss: 0.7993\n",
      "Epoch 38/64\n",
      "301/301 [==============================] - 384s 1s/step - loss: 0.7916\n",
      "Epoch 39/64\n",
      "301/301 [==============================] - 375s 1s/step - loss: 0.7850\n",
      "Epoch 40/64\n",
      "301/301 [==============================] - 370s 1s/step - loss: 0.7755\n",
      "Epoch 41/64\n",
      "301/301 [==============================] - 372s 1s/step - loss: 0.7688\n",
      "Epoch 42/64\n",
      "301/301 [==============================] - 373s 1s/step - loss: 0.7620\n",
      "Epoch 43/64\n",
      "301/301 [==============================] - 373s 1s/step - loss: 0.7571\n",
      "Epoch 44/64\n",
      "301/301 [==============================] - 372s 1s/step - loss: 0.7524\n",
      "Epoch 45/64\n",
      "301/301 [==============================] - 372s 1s/step - loss: 0.7437\n",
      "Epoch 46/64\n",
      "301/301 [==============================] - 376s 1s/step - loss: 0.7389\n",
      "Epoch 47/64\n",
      "301/301 [==============================] - 373s 1s/step - loss: 0.7328\n",
      "Epoch 48/64\n",
      "301/301 [==============================] - 373s 1s/step - loss: 0.7277\n",
      "Epoch 49/64\n",
      "301/301 [==============================] - 371s 1s/step - loss: 0.7242\n",
      "Epoch 50/64\n",
      "301/301 [==============================] - 372s 1s/step - loss: 0.7219\n",
      "Epoch 51/64\n",
      "301/301 [==============================] - 11728s 39s/step - loss: 0.7160\n",
      "Epoch 52/64\n",
      "301/301 [==============================] - 21116s 70s/step - loss: 0.7112\n",
      "Epoch 53/64\n",
      "301/301 [==============================] - 919s 3s/step - loss: 0.7089\n",
      "Epoch 54/64\n",
      "301/301 [==============================] - 455s 2s/step - loss: 0.7058\n",
      "Epoch 55/64\n",
      "301/301 [==============================] - 384s 1s/step - loss: 0.7044\n",
      "Epoch 56/64\n",
      "301/301 [==============================] - 388s 1s/step - loss: 0.6993\n",
      "Epoch 57/64\n",
      "301/301 [==============================] - 384s 1s/step - loss: 0.6971\n",
      "Epoch 58/64\n",
      "301/301 [==============================] - 376s 1s/step - loss: 0.6968\n",
      "Epoch 59/64\n",
      "301/301 [==============================] - 380s 1s/step - loss: 0.6920\n",
      "Epoch 60/64\n",
      "301/301 [==============================] - 390s 1s/step - loss: 0.6889\n",
      "Epoch 61/64\n",
      "301/301 [==============================] - 381s 1s/step - loss: 0.6846\n",
      "Epoch 62/64\n",
      "301/301 [==============================] - 390s 1s/step - loss: 0.6852\n",
      "Epoch 63/64\n",
      "301/301 [==============================] - 381s 1s/step - loss: 0.6837\n",
      "Epoch 64/64\n",
      "301/301 [==============================] - 389s 1s/step - loss: 0.6808\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs = 64, callbacks = [checkpoint,tb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cognitive-steam",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "convertible-peninsula",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 46540), started 0:03:52 ago. (Use '!kill 46540' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-ac3d9cf01653171\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-ac3d9cf01653171\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "equipped-object",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Predictive text generation/training_checkpoints\\\\ckpt_64'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorflow.train.latest_checkpoint(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "thermal-portsmouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(len(vocab),256,batch_input_shape= [1,None]))\n",
    "    model.add(GRU(1024, return_sequences = 'True', stateful = True, recurrent_initializer = 'glorot_uniform'))\n",
    "    model.add(GRU(128, return_sequences = 'True', stateful = True, recurrent_initializer = 'glorot_uniform'))\n",
    "    model.add(Dense(len(vocab)))\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "synthetic-marijuana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (1, None, 256)            16384     \n",
      "_________________________________________________________________\n",
      "gru_6 (GRU)                  (1, None, 1024)           3938304   \n",
      "_________________________________________________________________\n",
      "gru_7 (GRU)                  (1, None, 128)            443136    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (1, None, 64)             8256      \n",
      "=================================================================\n",
      "Total params: 4,406,080\n",
      "Trainable params: 4,406,080\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "entitled-special",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(tensorflow.train.latest_checkpoint(path))\n",
    "model.build(tensorflow.TensorShape([1,None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "hawaiian-algebra",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (1, None, 256)            16384     \n",
      "_________________________________________________________________\n",
      "gru_6 (GRU)                  (1, None, 1024)           3938304   \n",
      "_________________________________________________________________\n",
      "gru_7 (GRU)                  (1, None, 128)            443136    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (1, None, 64)             8256      \n",
      "=================================================================\n",
      "Total params: 4,406,080\n",
      "Trainable params: 4,406,080\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "manufactured-information",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, context, num_generate = 1000, temperature = 1.0):\n",
    "    input_eval = [chartoint[c] for c in context]\n",
    "    input_eval = tensorflow.expand_dims(input_eval, 0)\n",
    "    text_generated = []\n",
    "    model.reset_states()\n",
    "    \n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tensorflow.squeeze(predictions, 0)\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tensorflow.random.categorical(predictions, num_samples = 1)[-1,0].numpy()\n",
    "        input_eval = tensorflow.expand_dims([predicted_id],0)\n",
    "        text_generated.append(inttochar[predicted_id])\n",
    "        \n",
    "    return (context + ''.join(text_generated))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "described-snake",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the tea was made, resounding; seeping\n",
      "into a state of the parlry, “you did she got a fixed that you have occum sometimes to, the\n",
      "book-night. at such drew from a lives of anifore the moment he\n",
      "had got been forght” said the\n",
      "girl after a good further pipe, oliver and his new moments.\n",
      "innors what more left the matter. won’t scream of hig? i’ll go _lier? my dear. ye had the grat stances of beats\n",
      "malicious coughho the gentleman that new\n",
      "the orphan his hand who have hit with all his recistables than to this work.. “well, well give me; i’ve knowswas done, there so much so i don’t know. i don’t\n",
      "know what all, i don’t keep of this work. “if the what?” exclocked the jew.\n",
      "\n",
      "monks well ily full of paragning about the windows of those who must done for it, there’s no deny\n",
      "charge.”\n",
      "\n",
      "“what bolted, mrs. mann?” remained mrs. maylie.\n",
      "\n",
      "mr. brownlow in the dock; thinking, having lingered a old jew in\n",
      "the space. oliver “he was brought up the ttrance to such a\n",
      "light at doors.\n",
      "\n",
      "it was so much better the gentleman’s presently.\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model,\"the tea was made\", num_generate=1000, temperature=1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "incomplete-donna",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if the matron had moved her chair to the right she would have to the left,\n",
      "which count-temper. he took stealthily availly by love a long suppredent heart to the smallest cork over the nex tender\n",
      "who seemed the three medicine me; and that we led the company who\n",
      "turn it into\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model,\"if the matron had moved her chair to the right she would have to the left\", num_generate=200, temperature=0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "horizontal-texas",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
